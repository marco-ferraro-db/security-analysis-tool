{"searchDocs":[{"title":"Standard Install","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/standard/","content":"Standard Install Note SAT is a productivity tool to help verify security configurations of Databricks deployments, it's not meant to be used as certification or attestation of your deployments. SAT project is regularly updated to improve the correctness of checks, add new checks, and fix bugs. You will need a single SAT install per Databricks account in AWS and GCP and a single install per azure subscription in Azure. Add the Service principal as mentioned in the detailed steps to analyze the rest of the workspaces from the workspace where SAT is installed. You can choose not to add SP to a given workspace if you wish to ignore a given workspace. Please send your feedback and comments to sat@databricks.com. SAT can be setup on any of the cloud providers where Databricks is hosted. Follow the setup guide for the cloud provider you are using: AWS Setup GuideAzure Setup GuideGCP Setup Guide","keywords":"","version":"Next"},{"title":"Motivation","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/motivation/","content":"Motivation Security Analysis Tool (SAT) analyzes customer's Databricks account and workspace security configurations and provides recommendations that help them follow Databrick's security best practices. When a customer runs SAT, it will compare their workspace configurations against a set of security best practices and delivers a report for their Databricks (AWS, Azure, and GCP) workspaces. These checks identify recommendations to harden Databricks configurations, services, and resources. Databricks has worked with thousands of customers to securely deploy the Databricks platform, with the appropriate security features that meet their architecture requirements. While many organizations deploy security differently, there are guidelines and features that are commonly used by organizations that need a high level of security. This tool checks for typical security features that are deployed by most high-security organizations, and reviews the largest risks and the risks that customers ask about most often. It will then provide a security configuration reference link to Databricks documentation along with a recommendation. SAT is a productivity tool to help verify security configurations against security best practices of Databricks, its not meant to be used as a certification or an attestation of your deployments. Please review the SAT report with your business stakeholders, administrators, security team and auditors about SAT report and assess your organizational security requirements before making any security improvements bases on the report, not all deviations required to be mitigated. Some of the recommendations may have cost implications, some of the security features recommended may have dependency feature limitations, please thoroughly review individual feature documentation before making changes to your security configurations. SAT project is being regularly updated to improve correctness of checks, add new checks, fix bugs. Please send your feedback and comments to sat@databricks.com or open a git issue.","keywords":"","version":"Next"},{"title":"Terraform Install","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/terraform/","content":"Terraform Install SAT can be setup on any of the cloud providers where Databricks is hosted and can be installed using Terrafom. Follow the setup guide for the cloud provider you are using: AWS Terraform InstallAzure Terraform InstallGCP Terraform Install","keywords":"","version":"Next"},{"title":"Funtionality","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/functionality/","content":"","keywords":"","version":"Next"},{"title":"SAT Insights​","type":1,"pageTitle":"Funtionality","url":"/security-analysis-tool/docs/functionality/#sat-insights","content":" Data across any of the configured workspaces can be surfaced through a single pane of SQL Dashboard which is the primary consumption layer where all the insights are arranged in well defined categories namely:  Network SecurityIdentity &amp; AccessData ProtectionGovernanceInformational  The data in each section is further categorized by severity namely: High, Medium, Low.    The dashboard is broken into the five sections and each pillar is laid out in a consistent format.  Workspace Security Summary The high-level summary calls out findings by category, categorized by severity. Workspace Stats This section provides when the analysis was run, workspace name, and service details like tier and region. Individual Security Category Details A section for each security category that contains: Security section summary details, such as counts of deviations from recommended best practicesA table with security finding details for the security category, sorted by severity. The table describes each security violation and provides links to documentation that help to fix the finding. Informational Section These are less prescriptive in nature but provide data points that can be scrutinized by data personas to verify thresholds are set correctly for their organization. Additional Finding Details This section provides additional details that help to pinpoint the source of a security deviation, including the logic used to detect them. For example, the 'cluster policy not used' will provide a list of the cluster workloads where the policy is not applied, avoiding a needle-in-a-haystack situation.  ","version":"Next","tagName":"h2"},{"title":"Detection example​","type":1,"pageTitle":"Funtionality","url":"/security-analysis-tool/docs/functionality/#detection-example","content":" Security Analysis Tool (SAT) analyzes 60 best practices, with more on the way. In the example below, the SAT scan highlights one finding that surfaces a potential risk, and one that meets Databricks' best practices. The Deprecated runtime versions check is red indicating that there are runtimes that are deprecated. Workloads on unsupported runtime versions may continue to run, but they receive no Databricks support or fixes. The Remediation column in the screenshot describes the risk and links to the documentation of the Databricks runtime versions that are currently supported.  On the other hand, the Log delivery check is green, confirming that the workspace follows Databricks security best practices. Run these checks regularly to comprehensively view Databricks account workspace security and ensure continuous improvement.    Customers can use the &quot;Additional Details&quot; section to display information on what configuration setting or control failed a specific best practice rule. For example, the image below showcases additional details on the &quot;Deprecated runtime versions&quot; risk for administrators to investigate.    In the example below, the customer can know more about the “Log delivery” by inputting “GOV-3”.    ","version":"Next","tagName":"h2"},{"title":"Security Deviation Trend​","type":1,"pageTitle":"Funtionality","url":"/security-analysis-tool/docs/functionality/#security-deviation-trend","content":" This section shows the trend of security best practice deviations over a date range. This helps identify the inflection point where improvements or degradations started to aid the investigation and remediation. For example, the diagram below shows a count of deviations in various categories by run date. The expectation is that over time the height of these bar charts should shrink or, at best, remain the same. If there is a sudden increase, it warrants immediate investigation as it indicates a possible inadvertent human error.    ","version":"Next","tagName":"h2"},{"title":"Security Configuration Comparison​","type":1,"pageTitle":"Funtionality","url":"/security-analysis-tool/docs/functionality/#security-configuration-comparison","content":" This section gives ability to compare two runs side by side along each of the security dimensions. This drill-down option helps pinpoint the checks that have either been rectified or degraded, so that security folks can address them speedily. For example, The diagram below shows the individual checks in various categories for each run. The red recatngle in the diagram shows an improvement in “Enforce User Isolation” but degradation in the “Admin Count” best practice. The expectation is that over time the cross marks should chage to tick marks. If it is the opposite, it warrants immediate investigation as it indicates a degradation. An alert also will be triggered incase of detecting detrimental changes to notify via an email.    ","version":"Next","tagName":"h2"},{"title":"Configuration and Usage instructions​","type":1,"pageTitle":"Funtionality","url":"/security-analysis-tool/docs/functionality/#configuration-and-usage-instructions","content":" Refer to Standard setup guide or Terraform Guide to setup  Note SAT requires at least one SAT set up in a workspace per account in AWS or GCP and at least one SAT set up in a workspace per Azure subscription.  ","version":"Next","tagName":"h2"},{"title":"Project support​","type":1,"pageTitle":"Funtionality","url":"/security-analysis-tool/docs/functionality/#project-support","content":" Please note the code in this project is provided for your exploration only, and are not formally supported by Databricks with Service Level Agreements (SLAs). They are provided AS-IS and we do not make any guarantees of any kind. Please do not submit a support ticket relating to any issues arising from the use of these projects. The source in this project is provided subject to the Databricks LICENSE. All included or referenced third party libraries are subject to the licenses set forth below.  Any issues discovered through the use of this project should be filed as GitHub Issues on the Repo. They will be reviewed as time permits, but there are no formal SLAs for support. ","version":"Next","tagName":"h2"},{"title":"Installation","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Installation","url":"/security-analysis-tool/docs/installation/#prerequisites","content":" Note SAT is beneficial to customers on Databrics Premium or Enterprise as most of the checks and recommendations involve security features available in tiers higher than the Standard.  Before proceeding with the installation, make sure you have the following prerequisites:  Python 3.9 or higherDatabricks CLI installed with a profile logged (See here.)Databricks Account IDDatabricks SQL Warehouse (To run the SQL dashboard)Pypi access from your workspace (To install the SAT utility library)  Considerations SAT creates a new security_analysis schema and Delta tables. If you are an existing SAT user please run the following command: Hive metastore based schema​ drop database security_analysis cascade; Unity Catalog based schema​ drop database &lt;uc_catalog_name&gt;.&lt;schema_name&gt; cascade;   SAT can be setup on any of the cloud providers where Databricks is hosted. Follow the setup guide for the cloud provider you are using:  AWS Setup GuideAzure Setup GuideGCP Setup Guide  Terraform Install SAT can be setup as Terraform based deployment, if you use Terraform in your organization please prefer Terraform instructions: SAT AWS Terraform deploymentSAT Azure Terraform deploymentSAT GCP Terraform deployment ","version":"Next","tagName":"h2"},{"title":"GCP","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/standard/gcp/","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/standard/gcp/#prerequisites","content":" There are some pre-requisites that need to be met before you can setup SAT on GCP. Make sure you have the appropriate permissions in your GCP Cloud account to create the resources mentioned below.  SAT is beneficial to customers on Databrics Premium or Enterprise as most of the checks and recommendations involve security features available in tiers higher than the Standard.  ","version":"Next","tagName":"h2"},{"title":"Service Accounts​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/standard/gcp/#service-accounts","content":" The first step is to create a Service Principal in GCP. This will allow SAT to authenticate with GCP services. Follow the steps below to create a Service Principal:  Please follow this guide to create the required service accounts.Now upload the SA-1.json file into a GCS bucket.To add the service account to the Account Console: You will need to create a new user and add the service account email as the user email. The Service Principal must be granted the Account Admin role. This role provides the ability to manage account-level settings and permissions.Assign the Workspace Admin Role: The Service Principal must be assigned the Workspace Admin role for each workspace it will manage. This role provides the ability to manage workspace-level settings and permissions.Add to the Metastore Admin Group: The Service Principal must be added to the Metastore Admin group or role. This role provides the ability to manage metastore-level settings and permissions.  ","version":"Next","tagName":"h3"},{"title":"Databricks Service Principal​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/standard/gcp/#databricks-service-principal","content":" The first step is to create a Service Principal in Databricks. This will allow SAT to authenticate with the other workspaces. Follow the steps:  Go to the Account ConsoleOn the left side bar menu, click on User managementSelect Service Principal and then Add service principalType a new name for the service principal.The Service Principal must be granted the Account Admin role. This role provides the ability to manage account-level settings and permissions.Assign the Workspace Admin Role: The Service Principal must be assigned the Workspace Admin role for each workspace it will manage. This role provides the ability to manage workspace-level settings and permissions.Add to the Metastore Admin Group: The Service Principal must be added to the Metastore Admin group or role. This role provides the ability to manage metastore-level settings and permissions.Create a new OAuth Secret.Save the Secret and Client IDTo analyze a workspace with SAT, you must add the Service Principal to the workspace. Please add this Service Princple to each workspace so that SAT can access the APIs for analysis.  ","version":"Next","tagName":"h3"},{"title":"Installation​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/standard/gcp/#installation","content":" ","version":"Next","tagName":"h2"},{"title":"Credentials Needed​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/standard/gcp/#credentials-needed","content":" To setup SAT on GCP, you will need the following credentials:  Databricks Account IDService Account emailgsutil URI from GCS Bucket    To execute the SAT follow these steps on your workstation or a compatible VM that has access to the internet and the Databricks workspace:  Clone the SAT repository locally git clone https://github.com/databricks-industry-solutions/security-analysis-tool.git   To ensure that the install.sh script is executable, you need to modify its permissions using the chmod command.  For linux or mac users:  chmod +x install.sh   Remember that the target workspace should have a profile in Databricks CLI  Run the install.sh script on your terminal.    Congratulations! 🎉 You are now ready to start using SAT. Please click here for a detailed description on how to run and use it.  ","version":"Next","tagName":"h3"},{"title":"Troubleshooting​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/standard/gcp/#troubleshooting","content":" Please review the FAQs and Troubleshooting resources documented here including a notebook to help diagnose your SAT setup. If any issues arise during the installation process, please check your credentials and ensure that you have the appropriate permissions in your GCP cloud account. If you are still facing issues, please send your feedback and comments to sat/@databricks.com. ","version":"Next","tagName":"h2"},{"title":"FAQ","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/faq/","content":"","keywords":"","version":"Next"},{"title":"SAT Deployment and Support​","type":1,"pageTitle":"FAQ","url":"/security-analysis-tool/docs/faq/#sat-deployment-and-support","content":"   Is SAT an officially supported tool? SAT is not an officially supported tool. Any issues discovered through the use of this project should be filed as GitHub Issues on the repository. They will be reviewed as time permits, but there are no formal SLAs for support. Please note that the code in the SAT project is provided for your exploration only and is not formally supported by Databricks with Service Level Agreements (SLAs). It is provided AS-IS, and we do not make any guarantees of any kind. Please do not submit a support ticket relating to any issues arising from the use of these projects. The source in this project is provided subject to the Databricks License. All included or referenced third-party libraries are subject to the licenses set forth in the project license. Any issues discovered through the use of this project should be filed as GitHub Issues on the repository. They will be reviewed as time permits, but there are no formal SLAs for support. Can I open Databricks support tickets if I encounter issues with SAT? Currently, SAT is a self-service tool which is developed and maintained by Databricks field team. Please contact your Databricks account team and open a git issue if you run into issues. Can SAT be configured on an independent virtual machine? SAT needs to be deployed in one of your Databricks workspaces and run as a workflow. You can trigger the SAT installation process from any machine (Preferably Linux) where Databricks CLI and other prerequisites are available, installed and configured. Does SAT automatically update once I set up? SAT is frequently upgraded and the latest versions are made available in the official Git repository. SAT deployments do not automatically update on their own. To upgrade or update SAT deployments in your environment, you need to perform the update manually. This is a design decision, so that customers have full control on the upgrade process of SAT. Can SAT make modifications to my workspaces and account? SAT is meant to be a readonly analysis tool, it does not make changes to your workspace or account configurations. I am seeing errors when I run the SAT. How can I validate my SAT configuration? We have created diagnostic notebooks to help you verify if your SAT setup has the necessary configurations, permissions, and network paths to run the REST API calls. Please use “Workspace -&gt; Applications -&gt; SAT/TF -&gt; Files -&gt; Notebooks -&gt; Diagnosis” to find the appropriate notebook for your cloud. If SAT is already configured, how do we add/remove other workspaces in the same account/subscription? If the service principal configured to be used by SAT (credentials) is added to any workspace in the account/subscription, SAT will automatically collect details for all those workspaces as well. To achieve this, add or remove the credentials used by SAT to or from the workspace, and run the initialization job to register the new workspaces under SAT. If a workspace is deleted after the SAT is set up, is there a way to get the initializer to run without error without a full reinstall of the tool? You need to re-run the initializer, that will mark the workspace connection test as failed and will not be assessed in future. Another option is run this step if you want to manually remove the workspace I added a new workspace for analysis, re-ran steps under initialize and driver, but the dashboard is not updated with the new workspace in the pulldown even though I see new data generated by the analysis scan for the new workspace in SAT database. What should I do? It is likely that the dashboard cached the workspaces in the pulldown. You can go to SQL view of your workspace -&gt; Queries -&gt; find workspace_ids query and run it. This process should refresh the cache and you should have the new workspaces in the pull-down. Can I use one deployment of SAT to monitor all my workspaces across different clouds, like AWS and Azure? Currently one deployment of SAT in AWS can be used for monitoring all the workspaces in that AWS account. Similarly, one deployment of SAT in Azure can be used for monitoring all the workspaces in that Azure subscription. One deployment of SAT to monitor workspaces deployed across different clouds is currently not supported. Do I need different SAT deployment to monitor workspaces in different regions? One deployment of SAT in AWS can be used for monitoring all the workspaces (in any region) in that AWS account . Similarly, one deployment of SAT in Azure can be used for monitoring all the workspaces (in any region) in that Azure subscription. Can SAT be integrated with other cloud based monitoring tools? This is not supported at this time. SAT is a security monitoring tool used specifically for Databricks workspaces. There is an export notebook you can use to export the results of SAT that you can consider using with other tools.    ","version":"Next","tagName":"h2"},{"title":"SAT Checks​","type":1,"pageTitle":"FAQ","url":"/security-analysis-tool/docs/faq/#sat-checks","content":"   Does SAT test for all of the Databricks Security Best practices? We are continuously making improvements to SAT, and the majority of the checks are based on Security Best Practices. However, not all recommendations are covered, as some best practices are specific to cloud configuration, and a few practices can't be automatically checked due to the absence of REST APIs. What do the severity labels specifically mean on the SAT configs? How does one interpret them? Severity in the SAT report is our general assessment of what a given check means for most customers, allowing them to prioritize mitigating deviations starting with the 'High' severity ones first. However, each customer can assess the applicability of the severity and prioritize according to their own security needs.  ","version":"Next","tagName":"h2"},{"title":"","type":1,"pageTitle":"FAQ","url":"/security-analysis-tool/docs/faq/##","content":" Can I disable a check for my assessment?Yes, this is possible. Please follow the optional step, you can modify security best practices for the SAT checks. Go to “Workspace -&gt; Applications -&gt; SAT/TF -&gt; Files -&gt; Notebooks -&gt; Setup -&gt; 7. update_sat_check_configuration” and use this utility to enable/disable a check, modify evaluation value, and alert configuration value for each check. You can update this file at any time, and any analysis from then on will take these values into consideration.    ","version":"Next","tagName":"h2"},{"title":"SAT Reports​","type":1,"pageTitle":"FAQ","url":"/security-analysis-tool/docs/faq/#sat-reports","content":"   Do we need to address all of the deviations reported by SAT? Not necessarily. Please make sure to review the SAT report with your business stakeholders, administrators, security team, auditors, and other relevant parties. Assess your organizational security requirements before making any security improvements based on the report, as not all deviations need to be mitigated by all customers. Some of the recommendations may have cost implications, and some of the recommended security features may have dependencies or feature limitations. Please thoroughly review individual feature documentation before making changes to your security configurations Why are SSO, SCIM, Table ACLs etc not properly reflected in the SAT report? Please refer to the usage section of the setup guide. There are a few checks that rely on self-assessment due to the lack of REST APIs to automatically check them. Please go to “Workspace -&gt; Applications -&gt; SAT -&gt; Files -&gt; self_assessment_checks.yaml” and ensure the 'enabled' values reflect your environment for the listed manual checks with either true or false. SAT will automatically check the rest of the configurations. Rerun the SAT jobs.   ","version":"Next","tagName":"h2"},{"title":"AWS","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/terraform/aws/","content":"","keywords":"","version":"Next"},{"title":"Setting up Terraform​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/terraform/aws/#setting-up-terraform","content":" Note SAT v0.2.0 or higher brings full support for Unity Catalog. Now you can pick your catalog instead of hive_metastore. Plus, you get to choose your own schema name.  Step 1: Install Terraform  Step 2: Install Git on local machine  Step 3: Git Clone Repo   git clone https://github.com/databricks-industry-solutions/security-analysis-tool.git   Step 4: Change Directories   cd security-analysis-tool/terraform/&lt;cloud&gt;/   Step 5: Generate a terraform.tfvars file base on template.tfvars  Using any editor set the values in the terraform.tfvars file. The descriptions of all the variables are located in the variables.tf file. Once the variables are set you are ready to run Terraform.  Further Documentation for some of the variables:  workspace_id account_console_id  Proxies are now supported as part of SAT. You can add your HTTP and HTTPS links to use your proxies.  { &quot;http&quot;: &quot;http://example.com&quot;, &quot;https&quot;: &quot;https://example.com&quot; }   ","version":"Next","tagName":"h2"},{"title":"Run Terraform​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/terraform/aws/#run-terraform","content":" Step 6: Terraform Init  The terraform init command initializes a working directory containing configuration files and installs plugins for required providers.  terraform init   Step 7: Terraform Plan  The terraform plan command creates an execution plan, which lets you preview the changes that Terraform plans to make to your infrastructure. By default, when Terraform creates a plan it:  Reads the current state of any already-existing remote objects to make sure that the Terraform state is up-to-date. Compares the current configuration to the prior state and noting any differences. Proposes a set of change actions that should, if applied, make the remote objects match the configuration. terraform plan   Step 8: Terraform Apply  The terraform apply command executes the actions proposed in a Terraform plan.   terraform apply   Step 9: Run Jobs  You now have two jobs (SAT Initializer Notebook &amp; SAT Driver Notebook). Run SAT Initializer Notebook and when it completes run SAT Driver Notebook; SAT Initializer Notebook should only be run once (although you can run it multiple times, it only needs to be run successfully one time), and SAT Driver Notebook can be run periodically (its scheduled to run once every Monday, Wednesday, and Friday).  Step 10: SAT Dashboard  Go to the SQL persona, select the Dashboard icon in the left menu and then select the SAT Dashboard. Once the dashboard loads pick the Workspace from the dropdown and refresh the dashboard  Supplemental Documentation:  Databricks Documentation Terraform Databricks Terraform Provider Docs  ","version":"Next","tagName":"h2"},{"title":"Additional Considerations:​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/terraform/aws/#additional-considerations","content":" Your jobs may fail if there was a pre-existing secret scope named sat_scope when you run terraform apply. To remedy this, you will need to change the name of your secret scope in secrets.tf, re-run terraform apply, and then navigate to Workspace -&gt; Applications -&gt; SAT-TF -&gt;/notebooks/Utils/initialize and change the secret scope name in 6 places (3 times in CMD 4 and 3 times in CMD 5). You then can re-run your failed jobs.  Congratulations!!! Please review the setup documentation for the instructions on usage, FAQs and general understanding of SAT setup ","version":"Next","tagName":"h2"},{"title":"Azure","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/standard/azure/","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#prerequisites","content":" There are some pre-requisites that need to be met before you can setup SAT on Azure. Make sure you have the appropriate permissions in your Azure cloud account to create the resources mentioned below.  SAT is beneficial to customers on Databricks Premium or Enterprise as most of the checks and recommendations involve security features available in tiers higher than the Standard.  ","version":"Next","tagName":"h2"},{"title":"App Registration​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#app-registration","content":" The first step is to create an App Registration in Azure. This will allow SAT to authenticate with Azure services. Follow the steps below to create an App Registration:  Open the Azure portal and navigate to Microsoft Entra ID.Click on App registrations and then click on New registration.Enter a name for the App Registration and select the appropriate permissions. The minimum requirement is to have access in a single tenant.    ","version":"Next","tagName":"h3"},{"title":"App Client Secrets​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#app-client-secrets","content":" After creating the App Registration, you will need to create a client secret. This secret will be used to authenticate with Azure services. Follow the steps below to create a client secret:  Open the App Registration you created in the previous step.Click on Certificates &amp; secrets and then click on New client secret.Enter a description for the client secret and select the expiry date. Click on Add.Copy the value of the client secret and save it in a secure location.Please add the created app with &quot;Reader&quot; role into the subscription level via Access control (IAM) using Role assignments under your subscription, Access control (IAM) section    ","version":"Next","tagName":"h3"},{"title":"Add Service Principal to Databricks​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#add-service-principal-to-databricks","content":" After creating the App Registration and client secret, you will need to add the App Registration as a service principal in Databricks. Follow the steps below to add the service principal:  Go to the Account ConsoleOn the left side bar menu, click on User managementSelect Service Principal and then Add service principalSelect Microsoft Entra ID Managed Application as the service principal type.Paste the App Client ID and create a new name for the service principal.Click Add.The Service Principal must be granted the Account Admin role. This role provides the ability to manage account-level settings and permissions.Assign the Workspace Admin Role: The Service Principal must be assigned the Workspace Admin role for each workspace it will manage. This role provides the ability to manage workspace-level settings and permissions.Add to the Metastore Admin Group: The Service Principal must be added to the Metastore Admin group or role. This role provides the ability to manage metastore-level settings and permissions.    See the Databricks documentation for more information on adding service principals.  The Service Principal requires an Accounts Admin role, Admin role for each workspace and needs to be a member of the metastore admin group is required to analyze many of the APIs. Please add this Service Princple to each workspace so that SAT can access the APIs for analysis.  ","version":"Next","tagName":"h3"},{"title":"Installation​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#installation","content":" ","version":"Next","tagName":"h2"},{"title":"Credentials Needed​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#credentials-needed","content":" To setup SAT on Azure, you will need the following credentials:  Databricks Account IDAzure Tenant IDAzure Subscription IDAzure App Client ID (Obtained from App Registration)Azure App Client Secret (Obtained from App Client Secrets)  To execute the SAT follow these steps on your workstation or a compatible VM that has access to the internet and the Databricks workspace:  Clone the SAT repository locally git clone https://github.com/databricks-industry-solutions/security-analysis-tool.git   Remember that the target workspace should have a profile in Databricks CLI  Run the install.sh script on your terminal.  To ensure that the install.sh script is executable, you need to modify its permissions using the chmod command.   chmod +x install.sh ./install.sh     Congratulations! 🎉 You are now ready to start using the SAT. Please click here for a detailed description on how to run and use it.  ","version":"Next","tagName":"h3"},{"title":"Troubleshooting​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#troubleshooting","content":" Please review the FAQs and Troubleshooting resources documented here including a notebook to help diagnose your SAT setup. If any issues arise during the installation process, please check your credentials and ensure that you have the appropriate permissions in your Azure cloud account. If you are still facing issues, please send your feedback and comments to sat@databricks.com.  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/standard/azure/#references","content":" Azure App RegistrationDatabricks Service Principals ","version":"Next","tagName":"h2"},{"title":"AWS","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/standard/aws/","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/standard/aws/#prerequisites","content":" There are some prerequisites that need to be met before you can set up SAT on AWS. Make sure you have the appropriate permissions in your Databricks Account Console to create the resources mentioned below.  SAT is beneficial to customers on Databricks Premium or Enterprise as most of the checks and recommendations involve security features available in tiers higher than the Standard.  ","version":"Next","tagName":"h2"},{"title":"Service Principal​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/standard/aws/#service-principal","content":" The first step is to create a Service Principal in Databricks. This will allow SAT to authenticate with the other workspaces. Follow the steps:  Go to the Account ConsoleOn the left side bar menu, click on User managementSelect Service Principal and then Add service principalType a new name for the service principal.The Service Principal must be granted the Account Admin role. This role provides the ability to manage account-level settings and permissions.Assign the Workspace Admin Role: The Service Principal must be assigned the Workspace Admin role for each workspace it will manage. This role provides the ability to manage workspace-level settings and permissions.Add to the Metastore Admin Group: The Service Principal must be added to the Metastore Admin group or role. This role provides the ability to manage metastore-level settings and permissions.Create a new OAuth Secret.Save the Secret and Client IDTo deploy SAT in a workspace, you must add the Service Principal to the workspace.    The Service Principal requires an Accounts Admin role, Admin role for each workspace and needs to be a member of the metastore admin group is required to analyze many of the APIs. Please add this Service Princple to each workspace so that SAT can access the APIs for analysis.  ","version":"Next","tagName":"h3"},{"title":"Installation​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/standard/aws/#installation","content":" ","version":"Next","tagName":"h2"},{"title":"Credentials Needed​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/standard/aws/#credentials-needed","content":" To setup SAT on AWS, you will need the following credentials:  Databricks Account IDDatabricks Service Principal IDDatabricks Service Principal Secret  To execute the SAT follow these steps on your workstation or a compatible VM that has access to the internet and the Databricks workspace:  Clone the SAT repository locally git clone https://github.com/databricks-industry-solutions/security-analysis-tool.git   Remember that the target workspace should have a profile in Databricks CLI  Run the install.sh script on your terminal.  To ensure that the install.sh script is executable, you need to modify its permissions using the chmod command.   chmod +x install.sh ./install.sh   Proxies are now supported as part of SAT. You can add your HTTP and HTTPS links to use your proxies.    Congratulations! 🎉 You are now ready to start using the SAT. Please click here for a detailed description on how to run and use it.  ","version":"Next","tagName":"h3"},{"title":"Troubleshooting​","type":1,"pageTitle":"AWS","url":"/security-analysis-tool/docs/installation/standard/aws/#troubleshooting","content":" Please review the FAQs and Troubleshooting resources documented including a notebook to help diagnose your SAT setup. If any issues arise during the installation process, please check your credentials and ensure that you have the appropriate configurations and permissions for your Databricks. If you are still facing issues, please send your feedback and comments to sat@databricks.com. ","version":"Next","tagName":"h2"},{"title":"GCP","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/terraform/gcp/","content":"","keywords":"","version":"Next"},{"title":"Setting up Terraform​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/terraform/gcp/#setting-up-terraform","content":" Note SAT v0.2.0 or higher brings full support for Unity Catalog. Now you can pick your catalog instead of hive_metastore. Plus, you get to choose your own schema name.  Step 1: Install Terraform  Step 2: Install Git on local machine  Step 3: Git Clone Repo  git clone https://github.com/databricks-industry-solutions/security-analysis-tool.git   Step 4: Change Directories  cd security-analysis-tool/terraform/&lt;cloud&gt;/   Step 5: Generate a terraform.tfvars file base on template.tfvars  Using any editor set the values in the terraform.tfvars file. The descriptions of all the variables are located in the variables.tf file. Once the variables are set you are ready to run Terraform.  Further Documentation for some of the variables:  workspace_id  account_console_id  GCP Specific variables and navigate to the GCP section  Proxies are now supported as part of SAT. You can add your HTTP and HTTPS links to use your proxies.  { &quot;http&quot;: &quot;http://example.com&quot;, &quot;https&quot;: &quot;https://example.com&quot; }   ","version":"Next","tagName":"h2"},{"title":"Run Terraform​","type":1,"pageTitle":"GCP","url":"/security-analysis-tool/docs/installation/terraform/gcp/#run-terraform","content":" Step 6: Terraform Init  The terraform init command initializes a working directory containing configuration files and installs plugins for required providers.  terraform init   Step 7: Terraform Plan  The terraform plan command creates an execution plan, which lets you preview the changes that Terraform plans to make to your infrastructure. By default, when Terraform creates a plan it:  Reads the current state of any already-existing remote objects to make sure that the Terraform state is up-to-date.Compares the current configuration to the prior state and noting any differences.Proposes a set of change actions that should, if applied, make the remote objects match the configuration.  terraform plan   Step 8: Terraform Apply  The terraform apply command executes the actions proposed in a Terraform plan.  terraform apply   Step 9: Run Jobs  You now have two jobs (&quot;SAT Initializer Notebook&quot; &amp; &quot;SAT Driver Notebook&quot;). Run &quot;SAT Initializer Notebook&quot; and when it completes run &quot;SAT Driver Notebook&quot;. &quot;SAT Initializer Notebook&quot; should only be run once (although you can run it multiple times, it only needs to be run successfully one time), and &quot;SAT Driver Notebook&quot; can be run periodically (its scheduled to run once every Monday, Wednesday, and Friday).  Step 10: SAT Dashboard  Go to the SQL persona, select the Dashboard icon in the left menu and then select the SAT Dashboard. Once the dashboard loads pick the Workspace from the dropdown and refresh the dashboard  Supplemental Documentation:  Databricks Documentation Terraform  Databricks Terraform Provider Docs  Additional Considerations:  Your jobs may fail if there was a pre-existing secret scope named sat_scope when you run terraform apply. To remedy this, you will need to change the name of your secret scope in secrets.tf, re-run terraform apply, and then navigate to Workspace -&gt; Applications -&gt; SAT-TF /notebooks/Utils/initialize and change the secret scope name in 6 places (3 times in CMD 4 and 3 times in CMD 5). You then can re-run your failed jobs.  Congratulations!!! Please review the setup documentation for the instructions on usage, FAQs and general understanding of SAT setup ","version":"Next","tagName":"h2"},{"title":"Troubleshooting","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/troubleshooting/","content":"","keywords":"","version":"Next"},{"title":"Incorrectly configured secrets​","type":1,"pageTitle":"Troubleshooting","url":"/security-analysis-tool/docs/troubleshooting/#incorrectly-configured-secrets","content":" Error: Secret does not exist with scope: sat_scope and key: sat_tokens Resolution: Check if the tokens are configured with the correct names by listing and comparing with the configuration. databricks --profile e2-sat secrets list-secrets sat_scope   ","version":"Next","tagName":"h2"},{"title":"","type":1,"pageTitle":"Troubleshooting","url":"/security-analysis-tool/docs/troubleshooting/##","content":" ","version":"Next","tagName":"h2"},{"title":"Firewall blocking Databricks accounts console​","type":1,"pageTitle":"Troubleshooting","url":"/security-analysis-tool/docs/troubleshooting/#firewall-blocking-databricks-accounts-console","content":" Error: Traceback (most recent call last): File &quot;/databricks/python/lib/python3.8/site-packages/urllib3/connectionpool.py&quot;, line 670, in urlopen httplib_response = self._make_request( File &quot;/databricks/python/lib/python3.8/site-packages/urllib3/connectionpool.py&quot;, line 381, in _make_request self._validate_conn(conn) File &quot;/databricks/python/lib/python3.8/site-packages/urllib3/connectionpool.py&quot;, line 978, in _validate_conn conn.connect() File &quot;/databricks/python/lib/python3.8/site-packages/urllib3/connection.py&quot;, line 362, in connect self.sock = ssl_wrap_socket( File &quot;/databricks/python/lib/python3.8/site-packages/urllib3/util/ssl_.py&quot;, line 386, in ssl_wrap_socket return context.wrap_socket(sock, server_hostname=server_hostname) File &quot;/usr/lib/python3.8/ssl.py&quot;, line 500, in wrap_socket return self.sslsocket_class._create( File &quot;/usr/lib/python3.8/ssl.py&quot;, line 1040, in _create self.do_handshake() File &quot;/usr/lib/python3.8/ssl.py&quot;, line 1309, in do_handshake self._sslobj.do_handshake() ConnectionResetError: [Errno 104] Connection reset by peer During handling of the above exception, another exception occurred: Resolution: Run this following command in your notebook: %sh curl -X GET -H &quot;Authorization: Basic /&lt;base64 of userid:password/&gt;&quot; -H &quot;Content-Type: application/json&quot; https://accounts.cloud.databricks.com/api/2.0/accounts/&lt;account_id&gt;/workspaces or %sh curl -u 'user:password' -X GET &quot;Content-Type: application/json&quot; https://accounts.cloud.databricks.com/api/2.0/accounts/&lt;account_id&gt;/workspaces If you don’t see a JSON with a clean listing of workspaces, you are likely having a firewall issue that is blocking calls to the accounts console. Please have your infrastructure team add accounts.cloud.databricks.com to the allow-list. Ensure that the private IPv4 address from the NAT gateway is added to the IP allow list.  ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"Troubleshooting","url":"/security-analysis-tool/docs/troubleshooting/#-1","content":" ","version":"Next","tagName":"h2"},{"title":"Offline install of libraries in case of no PyPI access​","type":1,"pageTitle":"Troubleshooting","url":"/security-analysis-tool/docs/troubleshooting/#offline-install-of-libraries-in-case-of-no-pypi-access","content":" Steps: Download the dbl_sat_sdk version specified in the notebook notebooks/utils/initialize from PyPi: https://pypi.org/project/dbl-sat-sdk/ Upload the dbl_sat_sdk-w.x.y-py3-none-any.whl to a dbfs location. You can use the databricks-cli as one mechanism to upload. For example: databricks --profile e2-satfs cp /localdrive/whlfile/dbl_sat_sdk-w.x.y-py3-none-any.whl dbfs:/FileStore/wheels/ Additionally, download the following wheel files and upload them to the dbfs location as above: https://github.com/databricks-industry-solutions/security-analysis-tool/tree/main/docs/wheels Upload all wheel files to /FileStore/wheels in your workspace. Verify all files are there by running: %fs ls /FileStore/wheels Then change the cell in your notebook install_sat_sdk to this: %pip install cachetools --find-links /dbfs/FileStore/wheels/cachetools-5.3.1-py3-none-any.whl %pip install pyasn1 --find-links /dbfs/FileStore/wheels/pyasn1-0.5.0-py2.py3-none-any.whl %pip install pyasn1-modules --find-links /dbfs/FileStore/wheels/pyasn1_modules-0.3.0-py2.py3-none-any.whl %pip install rsa --find-links /dbfs/FileStore/wheels/rsa-4.9-py3-none-any.whl %pip install google-auth --find-links /dbfs/FileStore/wheels/google_auth-2.22.0-py2.py3-none-any.whl %pip install PyJWT[crypto] --find-links /dbfs/FileStore/wheels/PyJWT-2.8.0-py3-none-any.whl %pip install msal --find-links /dbfs/FileStore/wheels/msal-1.22.0-py2.py3-none-any.whl %pip install dbl-sat-sdk==0.1.37 --find-links /dbfs/FileStore/wheels/dbl_sat_sdk-0.1.37-py3-none-any.whl Make sure the versions for the above libraries match.   ","version":"Next","tagName":"h2"},{"title":"Azure","type":0,"sectionRef":"#","url":"/security-analysis-tool/docs/installation/terraform/azure/","content":"","keywords":"","version":"Next"},{"title":"Setting up Terraform for Azure​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#setting-up-terraform-for-azure","content":" Note SAT v0.2.0 or higher introduces full support for Unity Catalog. allowing you to pick your catalog instead of hive_metastore and customize your schema name.  Note SAT requires at least one SAT set up in a workspace per Azure subscription.  ","version":"Next","tagName":"h2"},{"title":"Step 1: Install Required Tools​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-1-install-required-tools","content":" Install Terraform.Install Git on your local machine.  ","version":"Next","tagName":"h3"},{"title":"Step 2: Clone the Repository​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-2-clone-the-repository","content":" Clone the Security Analysis Tool repository using:  git clone https://github.com/databricks-industry-solutions/security-analysis-tool.git   ","version":"Next","tagName":"h3"},{"title":"Step 3: Navigate to the Terraform Directory​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-3-navigate-to-the-terraform-directory","content":" Navigate to the relevant cloud directory:  cd security-analysis-tool/terraform/&lt;cloud&gt;/   ","version":"Next","tagName":"h3"},{"title":"Step 4: Configure Variables​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-4-configure-variables","content":" Create a terraform.tfvars file using the template.tfvars file as a base.Refer to the variables.tf for descriptions of the variables.Set all required variables for your deployment.  Azure-Specific Configuration​  Follow the Azure Setup Guide for variable setup.  Service Principal Role Requirements:​  &quot;Reader&quot; role at the subscription level via Access control (IAM).Accounts Admin roleAdmin role for each workspaceMember of the metastore admin group  Refer to the documentation for workspace_url, workspace_id, and account_console_id  ","version":"Next","tagName":"h3"},{"title":"Step 5: Configure Azure CLI Credentials​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-5-configure-azure-cli-credentials","content":" Set up Azure CLI credentials for the provider block in provider.tf.Use the Azure CLI to log in. The CLI will open a web browser for authentication:  az login   Proxies are now supported as part of SAT. You can add your HTTP and HTTPS links to use your proxies.  { &quot;http&quot;: &quot;http://example.com&quot;, &quot;https&quot;: &quot;https://example.com&quot; }   ","version":"Next","tagName":"h3"},{"title":"Step 6: Run Terraform Commands​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-6-run-terraform-commands","content":" Initialize Terraform:  terraform init   Plan Terraform Changes - create a plan to preview changes to your infrastructure:  terraform plan   Apply Terraform Plan - Execute the proposed changes:  terraform apply   ","version":"Next","tagName":"h3"},{"title":"Step 7: Run Databricks Jobs​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-7-run-databricks-jobs","content":" Run &quot;SAT Initializer Notebook&quot;:  This must be run successfully once. While it can be run multiple times, a single successful run is sufficient.  Run &quot;SAT Driver Notebook&quot;:  This notebook can be scheduled to run periodically (e.g., every Monday, Wednesday, and Friday).  ","version":"Next","tagName":"h3"},{"title":"Step 8: Access the SAT Dashboard​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#step-8-access-the-sat-dashboard","content":" Navigate to the SQL &gt; Dashboard in the left menu from the Databricks workspace.Select the SAT Dashboard, pic a Workspace from the dropdown, and refresh the dashboard.  ","version":"Next","tagName":"h3"},{"title":"Supplemental Documentation​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#supplemental-documentation","content":" Databricks Documentation TerraformDatabricks Terraform Provider Docs  ","version":"Next","tagName":"h3"},{"title":"Additional Considerations:​","type":1,"pageTitle":"Azure","url":"/security-analysis-tool/docs/installation/terraform/azure/#additional-considerations","content":" If a pre-existing secret scope named sat_scope causes jobs to fail:  Rename the secret scope in secrets.tfRe-run terraform apply.Update the secret scope name in 6 locations (CMD 4 and CMD 5) of Workspace -&gt; Applications -&gt; SAT-TF/notebooks/Utils/initialize.Re-run failed jobs  Congratulations!!! Please review the setup documentation for the instructions on usage, FAQs and general understanding of SAT setup ","version":"Next","tagName":"h3"}],"options":{"id":"default"}}